ğŸŒ Automated Macro-economic Data Analytics & Pipeline

End-to-end automated data pipeline for collecting, transforming, and analyzing global macroeconomic indicators to support data-driven economic insights and trend analysis.

ğŸ“Œ Contents

<a href="#overview">Overview</a>

<a href="#business-problem">Business Problem</a>

<a href="#data-sources">Data Sources</a>

<a href="#tools--technologies">Tools & Technologies</a>

<a href="#project-architecture">Project Architecture</a>

<a href="#project-structure">Project Structure</a>

<a href="#data-pipeline-workflow">Data Pipeline Workflow</a>

<a href="#dashboard--analytics">Dashboard & Analytics</a>

<a href="#key-insights">Key Insights</a>

<a href="#business-recommendations">Business Recommendations</a>

<a href="#how-to-run-this-project">How to Run This Project</a>

<a href="#author--contact">Author & Contact</a>

<h2><a class="anchor" id="overview"></a>Overview</h2>

This project builds a fully automated data pipeline to ingest, process, and analyze global macroeconomic indicators across countries and years. The solution integrates public economic APIs, applies structured data modeling, enforces data quality checks, and delivers interactive analytics through Power BI to support high-level economic trend evaluation and comparative analysis.

<h2><a class="anchor" id="business-problem"></a>Business Problem</h2>

Economic data is often fragmented across multiple sources, updated at different frequencies, and difficult to analyze consistently over time. Without a structured pipeline, analysts face challenges in:

Tracking long-term economic trends

Comparing indicators across countries

Ensuring data freshness and reliability

Supporting executive-level decision-making with trusted insights

This project addresses these challenges by building a scalable, automated, and auditable analytics pipeline.

<h2><a class="anchor" id="data-sources"></a>Data Sources</h2>

World Bank API â€“ Annual macroeconomic indicators (GDP, inflation, etc.)

FRED API â€“ Selected economic series for extensibility

Data is ingested programmatically using REST APIs and stored with ingestion timestamps for lineage tracking

<h2><a class="anchor" id="tools--technologies"></a>Tools & Technologies</h2>

Python (Requests, Pandas, Logging)

SQL / SQLite (Data modeling & transformations)

REST APIs (World Bank, FRED)

Power BI (Interactive analytics & executive reporting)

Windows Task Scheduler (Automation)

GitHub (Version control & project documentation)

<h2><a class="anchor" id="project-architecture"></a>Project Architecture</h2>

High-Level Flow:

APIs â†’ Raw Storage â†’ Data Validation â†’ Transformation Layer â†’ Analytics Tables â†’ Power BI Dashboard

The pipeline is modular, logged, and designed for incremental refresh without manual intervention.

<h2><a class="anchor" id="project-structure"></a>Project Structure</h2> 

```
economic-data-pipeline/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ economic_data.db
â”œâ”€â”€ run_pipeline.bat
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Raw ingested data
â”‚   â””â”€â”€ processed/               # Clean analytics-ready tables
â”‚
â”œâ”€â”€ scripts/                     # Python pipeline modules
â”‚   â”œâ”€â”€ ingest_worldbank.py
â”‚   â”œâ”€â”€ ingest_fred.py
â”‚   â”œâ”€â”€ transform_macro.py
â”‚   â”œâ”€â”€ data_quality.py
â”‚   â”œâ”€â”€ alert_email.py
â”‚   â”œâ”€â”€ incremental_load.py
â”‚   â”œâ”€â”€ run_pipeline.py
â”‚   â”œâ”€â”€ data_validation.py
â”‚   â”œâ”€â”€ export_analytics_tables.py
â”‚   â””â”€â”€ logger.py
    
â”‚
â”œâ”€â”€ sql/                         # SQL schema and transformations
â”‚   â””â”€â”€ transform_macro.sql
â”‚   â””â”€â”€ legacy_mysql_schema.sql
â”‚
â”œâ”€â”€ logs/                        # Pipeline execution logs
â”‚   â””â”€â”€ pipeline.log
â”‚   â””â”€â”€ pipeline_run.log
â”‚   â””â”€â”€ scheduler.log
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ economic_macro_model.pbix
â”‚   â””â”€â”€ dashboard.png
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture.png
â”‚   â””â”€â”€ log_screenshot.png
â”‚
â”œâ”€â”€ Automated Data Pipeline report.docx
â”‚
â”œâ”€â”€ Automated Data Pipeline.pptx
```

<h2><a class="anchor" id="data-pipeline-workflow"></a>Data Pipeline Workflow</h2>

Automated extraction from public APIs

Raw data stored without modification (source-of-truth)

Data quality validation (nulls, invalid values, schema checks)

Transformation into fact and dimension tables

Incremental loading to avoid reprocessing historical data

Centralized logging and failure alerts

Scheduled execution using Task Scheduler

<h2><a class="anchor" id="dashboard--analytics"></a>Dashboard & Analytics</h2>

The Power BI dashboard enables:

Long-term trend analysis across years

Country-wise and indicator-wise comparisons

Growth rate evaluation analysis

Dynamic filtering without reprocessing data

Key Views Include:

Aggregate economic value trends

Country contribution analysis

Indicator-level growth patterns

Year-over-year comparisons

![economic data pipeline Dashboard](dashboard/dashboard.png)

<h2><a class="anchor" id="key-insights"></a>Key Insights</h2>

Long-Term Aggregate Value Has Grown Consistently Over Time

Recent Period Shows Meaningful Year-over-Year Growth (3.69%)

Latest Year Contribution Is a Significant Share of Historical Total (60.12T)

Country Contribution Is Highly Skewed

Growth Rates Fluctuate Meaningfully Across Years

Automation Enables Multi-Dimensional Filtering Without Reprocessing

â€œUSâ€ consistently contribute higher aggregate values across indicators


<h2><a class="anchor" id="business-recommendations"></a>Business Recommendations</h2>

Prioritize indicators with sustained positive growth

Use rolling averages to reduce volatility bias

Support aggregate trends with indicator-level analysis

Maintain automated refresh for decision readiness

Extend the solution with forecasting and scenario modeling

<h2><a class="anchor" id="how-to-run-this-project"></a>How to Run This Project</h2>

Clone the repository:
```bash
git clone https://github.com/yourusername/economic-data-pipeline.git
```

Navigate to project directory:
```bash
cd economic-data-pipeline
```

Run the pipeline manually:
```bash
python scripts/run_pipeline.py
```

(Optional) Schedule execution:

- `Use run_pipeline.bat with Windows Task Scheduler for automation`

Open the Power BI dashboard:

- `dashboard/economic_macro_model.pbix`

---
<h2><a class="anchor" id="author--contact"></a>Author & Contact</h2>

**Prasanth Reddy Majji**  
Data Analyst  
ğŸ“§ Email: majjiprasanthreddy@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/prasanthreddymajji/)  
